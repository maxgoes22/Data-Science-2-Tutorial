{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding - Solutions\n",
    "\n",
    "In this tutorial we will be working with the transcriptions of general debates at the United Nations from 1970 to 2016. We will try to see whether the fall of the iron curtain changed the debates.\n",
    "\n",
    "For now, we'll just focus on the representation of the general debeates using various methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "InstallPackages = False\n",
    "if InstallPackages:\n",
    "    !pip install pandas\n",
    "    !pip install numpy\n",
    "    !pip install scikit-learn\n",
    "    !pip install spacy\n",
    "    !pip install gensim\n",
    "    !pip install seaborn\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from gensim.corpora import Dictionary\n",
    "import spacy\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Please, download the .bin file from the following website: https://fasttext.cc/docs/en/crawl-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = load_facebook_model('Models/cc.en.300.bin')\n",
    "ft_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data\n",
    "Read in the pre-processed 02.1 un-general-debates.csv file and set it to a data frame called df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/03.1 un-general-debates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use info on df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7507 entries, 0 to 7506\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   session   7507 non-null   int64 \n",
      " 1   year      7507 non-null   int64 \n",
      " 2   country   7507 non-null   object\n",
      " 3   text      7507 non-null   object\n",
      " 4   document  7507 non-null   object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 293.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the head of ad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>MDV</td>\n",
       "      <td>﻿It is indeed a pleasure for me and the member...</td>\n",
       "      <td>indeed pleasure member delegation extend ambas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>FIN</td>\n",
       "      <td>﻿\\nMay I begin by congratulating you. Sir, on ...</td>\n",
       "      <td>may begin congratulate sir election presidency...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>NER</td>\n",
       "      <td>﻿\\nMr. President, it is a particular pleasure ...</td>\n",
       "      <td>mr president particular pleasure behalf delega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>URY</td>\n",
       "      <td>﻿\\nDuring the debate at the fortieth session o...</td>\n",
       "      <td>debate fortieth session general assembly four ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>﻿I should like at the outset to express my del...</td>\n",
       "      <td>like outset express delegation satisfaction pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session  year country                                               text  \\\n",
       "0       44  1989     MDV  ﻿It is indeed a pleasure for me and the member...   \n",
       "1       44  1989     FIN  ﻿\\nMay I begin by congratulating you. Sir, on ...   \n",
       "2       44  1989     NER  ﻿\\nMr. President, it is a particular pleasure ...   \n",
       "3       44  1989     URY  ﻿\\nDuring the debate at the fortieth session o...   \n",
       "4       44  1989     ZWE  ﻿I should like at the outset to express my del...   \n",
       "\n",
       "                                            document  \n",
       "0  indeed pleasure member delegation extend ambas...  \n",
       "1  may begin congratulate sir election presidency...  \n",
       "2  mr president particular pleasure behalf delega...  \n",
       "3  debate fortieth session general assembly four ...  \n",
       "4  like outset express delegation satisfaction pl...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will focus on the German states, the United states of America and Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = df['country'].isin(['DDR','DEU','USA','RUS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[where]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Write functions to vectorize the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(docs):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to vectorize the corpus.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    vectorized = []\n",
    "    for tokens in docs:\n",
    "        zero_vector = np.zeros(ft_dim)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in ft_model.wv.key_to_index:\n",
    "                try:\n",
    "                    vectors.append(ft_model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            vectorized.append(avg_vec)\n",
    "            \"\"\"\n",
    "            if len(tokens) > 1:\n",
    "                print('tokens:', tokens)\n",
    "                for i, vec in enumerate(vectors):\n",
    "                    print('vec for %s:' % tokens[i], vec)\n",
    "                print('avg:', avg_vec)\n",
    "                print('val for avg[0]:', avg_vec[0])\n",
    "                temp = [x[0] for x in vectors]\n",
    "                print('first vals:', temp)\n",
    "                print('avg first vals:', numpy.mean(temp))\n",
    "            \"\"\"\n",
    "        else:\n",
    "            vectorized.append(zero_vector)\n",
    "    return vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Conduct the vectorization of the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not it's time to conduct the vectorization of the documents and to see the dimension of the vectorization as well as the number of documents vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = vectorize(df['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#representation of a document\n",
    "len(vectorized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of documents\n",
    "len(vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add topics over documents to Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Add topics over documents to the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add vectors to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.474364</td>\n",
       "      <td>-0.177181</td>\n",
       "      <td>-0.115030</td>\n",
       "      <td>0.064566</td>\n",
       "      <td>0.080548</td>\n",
       "      <td>-0.432402</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054978</td>\n",
       "      <td>-0.011042</td>\n",
       "      <td>-0.422587</td>\n",
       "      <td>0.117365</td>\n",
       "      <td>-0.045470</td>\n",
       "      <td>0.060640</td>\n",
       "      <td>0.070408</td>\n",
       "      <td>0.433676</td>\n",
       "      <td>-0.180066</td>\n",
       "      <td>-0.006274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045170</td>\n",
       "      <td>-0.479347</td>\n",
       "      <td>-0.176777</td>\n",
       "      <td>-0.114831</td>\n",
       "      <td>0.058033</td>\n",
       "      <td>0.077568</td>\n",
       "      <td>-0.435678</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054311</td>\n",
       "      <td>-0.012711</td>\n",
       "      <td>-0.420422</td>\n",
       "      <td>0.120504</td>\n",
       "      <td>-0.047409</td>\n",
       "      <td>0.063532</td>\n",
       "      <td>0.071119</td>\n",
       "      <td>0.437064</td>\n",
       "      <td>-0.180782</td>\n",
       "      <td>-0.006327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042098</td>\n",
       "      <td>-0.477911</td>\n",
       "      <td>-0.177789</td>\n",
       "      <td>-0.111894</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.085932</td>\n",
       "      <td>-0.438042</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047986</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>-0.423469</td>\n",
       "      <td>0.119311</td>\n",
       "      <td>-0.038719</td>\n",
       "      <td>0.060234</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.430105</td>\n",
       "      <td>-0.182800</td>\n",
       "      <td>0.004314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040613</td>\n",
       "      <td>-0.473045</td>\n",
       "      <td>-0.178341</td>\n",
       "      <td>-0.113857</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>0.076385</td>\n",
       "      <td>-0.427757</td>\n",
       "      <td>0.025394</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056330</td>\n",
       "      <td>-0.014192</td>\n",
       "      <td>-0.422098</td>\n",
       "      <td>0.120440</td>\n",
       "      <td>-0.044725</td>\n",
       "      <td>0.063443</td>\n",
       "      <td>0.071703</td>\n",
       "      <td>0.433857</td>\n",
       "      <td>-0.181058</td>\n",
       "      <td>-0.005857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039868</td>\n",
       "      <td>-0.468658</td>\n",
       "      <td>-0.175847</td>\n",
       "      <td>-0.115713</td>\n",
       "      <td>0.068617</td>\n",
       "      <td>0.079759</td>\n",
       "      <td>-0.427061</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050403</td>\n",
       "      <td>-0.012078</td>\n",
       "      <td>-0.421168</td>\n",
       "      <td>0.113696</td>\n",
       "      <td>-0.041331</td>\n",
       "      <td>0.061586</td>\n",
       "      <td>0.071667</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>-0.177153</td>\n",
       "      <td>-0.003478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.041443</td>\n",
       "      <td>-0.472530</td>\n",
       "      <td>-0.179367</td>\n",
       "      <td>-0.114636</td>\n",
       "      <td>0.064991</td>\n",
       "      <td>0.076231</td>\n",
       "      <td>-0.428124</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>-0.015615</td>\n",
       "      <td>-0.421761</td>\n",
       "      <td>0.119955</td>\n",
       "      <td>-0.043128</td>\n",
       "      <td>0.061627</td>\n",
       "      <td>0.071682</td>\n",
       "      <td>0.435125</td>\n",
       "      <td>-0.180907</td>\n",
       "      <td>-0.008896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.044541</td>\n",
       "      <td>-0.473861</td>\n",
       "      <td>-0.176111</td>\n",
       "      <td>-0.113395</td>\n",
       "      <td>0.065062</td>\n",
       "      <td>0.073943</td>\n",
       "      <td>-0.434651</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052061</td>\n",
       "      <td>-0.010522</td>\n",
       "      <td>-0.423800</td>\n",
       "      <td>0.118548</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>0.066871</td>\n",
       "      <td>0.069289</td>\n",
       "      <td>0.435122</td>\n",
       "      <td>-0.181913</td>\n",
       "      <td>-0.004838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.043971</td>\n",
       "      <td>-0.471412</td>\n",
       "      <td>-0.176335</td>\n",
       "      <td>-0.110895</td>\n",
       "      <td>0.066081</td>\n",
       "      <td>0.074975</td>\n",
       "      <td>-0.422528</td>\n",
       "      <td>0.026734</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060910</td>\n",
       "      <td>-0.019040</td>\n",
       "      <td>-0.428539</td>\n",
       "      <td>0.118366</td>\n",
       "      <td>-0.040926</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.069541</td>\n",
       "      <td>0.426809</td>\n",
       "      <td>-0.173203</td>\n",
       "      <td>-0.005083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.047017</td>\n",
       "      <td>-0.470673</td>\n",
       "      <td>-0.177591</td>\n",
       "      <td>-0.110135</td>\n",
       "      <td>0.060646</td>\n",
       "      <td>0.072362</td>\n",
       "      <td>-0.430308</td>\n",
       "      <td>0.024766</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058805</td>\n",
       "      <td>-0.014152</td>\n",
       "      <td>-0.424705</td>\n",
       "      <td>0.119273</td>\n",
       "      <td>-0.039459</td>\n",
       "      <td>0.065795</td>\n",
       "      <td>0.067146</td>\n",
       "      <td>0.437436</td>\n",
       "      <td>-0.178875</td>\n",
       "      <td>-0.003260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.045586</td>\n",
       "      <td>-0.472067</td>\n",
       "      <td>-0.176680</td>\n",
       "      <td>-0.111250</td>\n",
       "      <td>0.064202</td>\n",
       "      <td>0.078444</td>\n",
       "      <td>-0.436191</td>\n",
       "      <td>0.020851</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051438</td>\n",
       "      <td>-0.013885</td>\n",
       "      <td>-0.424830</td>\n",
       "      <td>0.115276</td>\n",
       "      <td>-0.036413</td>\n",
       "      <td>0.065198</td>\n",
       "      <td>0.067539</td>\n",
       "      <td>0.436318</td>\n",
       "      <td>-0.180885</td>\n",
       "      <td>-0.000039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.041803 -0.474364 -0.177181 -0.115030  0.064566  0.080548 -0.432402   \n",
       "1    0.045170 -0.479347 -0.176777 -0.114831  0.058033  0.077568 -0.435678   \n",
       "2    0.042098 -0.477911 -0.177789 -0.111894  0.065718  0.085932 -0.438042   \n",
       "3    0.040613 -0.473045 -0.178341 -0.113857  0.065143  0.076385 -0.427757   \n",
       "4    0.039868 -0.468658 -0.175847 -0.115713  0.068617  0.079759 -0.427061   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "147  0.041443 -0.472530 -0.179367 -0.114636  0.064991  0.076231 -0.428124   \n",
       "148  0.044541 -0.473861 -0.176111 -0.113395  0.065062  0.073943 -0.434651   \n",
       "149  0.043971 -0.471412 -0.176335 -0.110895  0.066081  0.074975 -0.422528   \n",
       "150  0.047017 -0.470673 -0.177591 -0.110135  0.060646  0.072362 -0.430308   \n",
       "151  0.045586 -0.472067 -0.176680 -0.111250  0.064202  0.078444 -0.436191   \n",
       "\n",
       "          7         8         9    ...       290       291       292  \\\n",
       "0    0.023970  0.002197  0.005664  ...  0.054978 -0.011042 -0.422587   \n",
       "1    0.026247  0.000754  0.005336  ...  0.054311 -0.012711 -0.420422   \n",
       "2    0.016039 -0.001096  0.008730  ...  0.047986 -0.007814 -0.423469   \n",
       "3    0.025394  0.000688  0.005907  ...  0.056330 -0.014192 -0.422098   \n",
       "4    0.021308  0.001091  0.005531  ...  0.050403 -0.012078 -0.421168   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "147  0.026487  0.000383  0.004232  ...  0.058600 -0.015615 -0.421761   \n",
       "148  0.023403  0.000180  0.006896  ...  0.052061 -0.010522 -0.423800   \n",
       "149  0.026734  0.002478  0.006643  ...  0.060910 -0.019040 -0.428539   \n",
       "150  0.024766  0.000785  0.008610  ...  0.058805 -0.014152 -0.424705   \n",
       "151  0.020851  0.000117  0.009354  ...  0.051438 -0.013885 -0.424830   \n",
       "\n",
       "          293       294       295       296       297       298       299  \n",
       "0    0.117365 -0.045470  0.060640  0.070408  0.433676 -0.180066 -0.006274  \n",
       "1    0.120504 -0.047409  0.063532  0.071119  0.437064 -0.180782 -0.006327  \n",
       "2    0.119311 -0.038719  0.060234  0.067308  0.430105 -0.182800  0.004314  \n",
       "3    0.120440 -0.044725  0.063443  0.071703  0.433857 -0.181058 -0.005857  \n",
       "4    0.113696 -0.041331  0.061586  0.071667  0.439560 -0.177153 -0.003478  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "147  0.119955 -0.043128  0.061627  0.071682  0.435125 -0.180907 -0.008896  \n",
       "148  0.118548 -0.041915  0.066871  0.069289  0.435122 -0.181913 -0.004838  \n",
       "149  0.118366 -0.040926  0.064805  0.069541  0.426809 -0.173203 -0.005083  \n",
       "150  0.119273 -0.039459  0.065795  0.067146  0.437436 -0.178875 -0.003260  \n",
       "151  0.115276 -0.036413  0.065198  0.067539  0.436318 -0.180885 -0.000039  \n",
       "\n",
       "[152 rows x 300 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(map(np.ravel, vectorized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,pd.DataFrame(list(map(np.ravel, vectorized)))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>RUS</td>\n",
       "      <td>﻿My task as head of the delegation of the Sovi...</td>\n",
       "      <td>task head delegation soviet union general asse...</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.474364</td>\n",
       "      <td>-0.177181</td>\n",
       "      <td>-0.115030</td>\n",
       "      <td>0.064566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054978</td>\n",
       "      <td>-0.011042</td>\n",
       "      <td>-0.422587</td>\n",
       "      <td>0.117365</td>\n",
       "      <td>-0.045470</td>\n",
       "      <td>0.060640</td>\n",
       "      <td>0.070408</td>\n",
       "      <td>0.433676</td>\n",
       "      <td>-0.180066</td>\n",
       "      <td>-0.006274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>DEU</td>\n",
       "      <td>﻿\\nI congratulate you, Sir, on your election a...</td>\n",
       "      <td>congratulate sir election president general as...</td>\n",
       "      <td>0.045170</td>\n",
       "      <td>-0.479347</td>\n",
       "      <td>-0.176777</td>\n",
       "      <td>-0.114831</td>\n",
       "      <td>0.058033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054311</td>\n",
       "      <td>-0.012711</td>\n",
       "      <td>-0.420422</td>\n",
       "      <td>0.120504</td>\n",
       "      <td>-0.047409</td>\n",
       "      <td>0.063532</td>\n",
       "      <td>0.071119</td>\n",
       "      <td>0.437064</td>\n",
       "      <td>-0.180782</td>\n",
       "      <td>-0.006327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>USA</td>\n",
       "      <td>﻿I am honoured to address the General Assembly...</td>\n",
       "      <td>honour address general assembly today beginnin...</td>\n",
       "      <td>0.042098</td>\n",
       "      <td>-0.477911</td>\n",
       "      <td>-0.177789</td>\n",
       "      <td>-0.111894</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047986</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>-0.423469</td>\n",
       "      <td>0.119311</td>\n",
       "      <td>-0.038719</td>\n",
       "      <td>0.060234</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.430105</td>\n",
       "      <td>-0.182800</td>\n",
       "      <td>0.004314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>DDR</td>\n",
       "      <td>﻿May I congratulate you, Sir, on your election...</td>\n",
       "      <td>may congratulate sir election president forty ...</td>\n",
       "      <td>0.040613</td>\n",
       "      <td>-0.473045</td>\n",
       "      <td>-0.178341</td>\n",
       "      <td>-0.113857</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056330</td>\n",
       "      <td>-0.014192</td>\n",
       "      <td>-0.422098</td>\n",
       "      <td>0.120440</td>\n",
       "      <td>-0.044725</td>\n",
       "      <td>0.063443</td>\n",
       "      <td>0.071703</td>\n",
       "      <td>0.433857</td>\n",
       "      <td>-0.181058</td>\n",
       "      <td>-0.005857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.\\t It is my privilege to extend to you once ...</td>\n",
       "      <td>1 privilege extend warm congratulation united ...</td>\n",
       "      <td>0.039868</td>\n",
       "      <td>-0.468658</td>\n",
       "      <td>-0.175847</td>\n",
       "      <td>-0.115713</td>\n",
       "      <td>0.068617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050403</td>\n",
       "      <td>-0.012078</td>\n",
       "      <td>-0.421168</td>\n",
       "      <td>0.113696</td>\n",
       "      <td>-0.041331</td>\n",
       "      <td>0.061586</td>\n",
       "      <td>0.071667</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>-0.177153</td>\n",
       "      <td>-0.003478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   session  year country                                               text  \\\n",
       "0       44  1989     RUS  ﻿My task as head of the delegation of the Sovi...   \n",
       "1       44  1989     DEU  ﻿\\nI congratulate you, Sir, on your election a...   \n",
       "2       44  1989     USA  ﻿I am honoured to address the General Assembly...   \n",
       "3       44  1989     DDR  ﻿May I congratulate you, Sir, on your election...   \n",
       "4       25  1970     USA  1.\\t It is my privilege to extend to you once ...   \n",
       "\n",
       "                                            document         0         1  \\\n",
       "0  task head delegation soviet union general asse...  0.041803 -0.474364   \n",
       "1  congratulate sir election president general as...  0.045170 -0.479347   \n",
       "2  honour address general assembly today beginnin...  0.042098 -0.477911   \n",
       "3  may congratulate sir election president forty ...  0.040613 -0.473045   \n",
       "4  1 privilege extend warm congratulation united ...  0.039868 -0.468658   \n",
       "\n",
       "          2         3         4  ...       290       291       292       293  \\\n",
       "0 -0.177181 -0.115030  0.064566  ...  0.054978 -0.011042 -0.422587  0.117365   \n",
       "1 -0.176777 -0.114831  0.058033  ...  0.054311 -0.012711 -0.420422  0.120504   \n",
       "2 -0.177789 -0.111894  0.065718  ...  0.047986 -0.007814 -0.423469  0.119311   \n",
       "3 -0.178341 -0.113857  0.065143  ...  0.056330 -0.014192 -0.422098  0.120440   \n",
       "4 -0.175847 -0.115713  0.068617  ...  0.050403 -0.012078 -0.421168  0.113696   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.045470  0.060640  0.070408  0.433676 -0.180066 -0.006274  \n",
       "1 -0.047409  0.063532  0.071119  0.437064 -0.180782 -0.006327  \n",
       "2 -0.038719  0.060234  0.067308  0.430105 -0.182800  0.004314  \n",
       "3 -0.044725  0.063443  0.071703  0.433857 -0.181058 -0.005857  \n",
       "4 -0.041331  0.061586  0.071667  0.439560 -0.177153 -0.003478  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Write functions to find the number of clusters using k-means\n",
    "\n",
    "**Note:** Get the number of clusters using the elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_method(Y_sklearn):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to get the optimal number of clusters in order to feed to the k-means clustering algorithm.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #algorithm{“lloyd”, “elkan”, “auto”, “full”}, default=”lloyd” per default: The classical EM-style algorithm is \"lloyd\".\n",
    "\n",
    "    number_clusters = range(1, 11)  # Range of possible clusters that can be generated\n",
    "    kmeans = [KMeans(n_clusters=i, max_iter = 600,random_state=seed) for i in number_clusters] # Getting no. of clusters \n",
    "\n",
    "    score = [kmeans[i].fit(Y_sklearn).score(Y_sklearn) for i in range(len(kmeans))] # Getting score corresponding to each cluster.\n",
    "    score = [i*-1 for i in score] # Getting list of positive scores.\n",
    "    \n",
    "    #score = sum of distances of samples to their closest cluster center. distance = euclidian distance\n",
    "    \n",
    "    plt.locator_params(axis='y', nbins=12)\n",
    "    plt.locator_params(axis='x', nbins=10)\n",
    "    \n",
    "    plt.plot(number_clusters, score)\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Sum of Distances')\n",
    "    #plt.title('Elbow Method')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 - Conduct the k-means, add it to the data frame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to conduct the k-means.\n",
    "\n",
    "First, find the number of clusters.\n",
    "\n",
    "Second, build the model.\n",
    "\n",
    "Third, add it to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the number of clusters\n",
    "#elbow_method(df.loc[:, '0':'299'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of clusters: result from elbow method\n",
    "nclusters = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maximilian Andres\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#build k means model\n",
    "km = KMeans(n_clusters=nclusters, init='k-means++', max_iter=600, random_state=seed, n_init=10).fit(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#documents to cluster assignment\n",
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['k_means_cluster']=km.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 - See what are the top n tokens in each cluster\n",
    "\n",
    "*Hint:* You may write a function returning you the top n tokens in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \n",
    "    \"\"\"\n",
    "    vec = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\").fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "united 2077\n",
      "states 1736\n",
      "nations 1490\n",
      "international 1409\n",
      "world 1177\n",
      "people 1080\n",
      "peace 1014\n",
      "country 960\n",
      "security 946\n",
      "soviet 894\n",
      "nuclear 890\n",
      "weapon 709\n",
      "union 708\n",
      "would 688\n",
      "must 685\n",
      "state 624\n",
      "make 618\n",
      "republic 607\n",
      "war 570\n",
      "general 560\n"
     ]
    }
   ],
   "source": [
    "common_words = get_top_n_words(df.loc[km.labels_==1]['document'], 20)\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 - Visualize the k-means\n",
    "\n",
    "**Note:** You may use a PCA with two components to visualize the k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduced_data = PCA(n_components=2).fit_transform(vectorized)\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=nclusters, n_init=10)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centroids are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
